{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zarifi/3311/blob/master/Copy_of_assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69mpn6Uvg9ke",
        "outputId": "1731646a-2255-4ef9-bb39-98aa347cd5df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'MSZoning': {'RL', 'C (all)', 'FV', 'RM', 'RH'}, 'Street': {'Grvl', 'Pave'}, 'Alley': {'Grvl', 'Pave', 'NA'}, 'LotShape': {'IR1', 'IR2', 'IR3', 'Reg'}, 'LandContour': {'Lvl', 'Low', 'HLS', 'Bnk'}, 'Utilities': {'NoSeWa', 'AllPub'}, 'LotConfig': {'FR2', 'CulDSac', 'FR3', 'Inside', 'Corner'}, 'LandSlope': {'Mod', 'Sev', 'Gtl'}, 'Neighborhood': {'Edwards', 'StoneBr', 'Somerst', 'Gilbert', 'Sawyer', 'NoRidge', 'NWAmes', 'NridgHt', 'CollgCr', 'Blueste', 'BrkSide', 'Mitchel', 'NPkVill', 'SWISU', 'Timber', 'OldTown', 'SawyerW', 'IDOTRR', 'MeadowV', 'Crawfor', 'ClearCr', 'NAmes', 'Blmngtn', 'Veenker', 'BrDale'}, 'Condition1': {'Artery', 'Feedr', 'RRNe', 'RRNn', 'PosA', 'PosN', 'Norm', 'RRAn', 'RRAe'}, 'Condition2': {'Artery', 'Feedr', 'RRNn', 'PosA', 'PosN', 'Norm', 'RRAn', 'RRAe'}, 'BldgType': {'2fmCon', '1Fam', 'Duplex', 'Twnhs', 'TwnhsE'}, 'HouseStyle': {'2Story', '2.5Unf', 'SFoyer', '1.5Unf', 'SLvl', '1.5Fin', '1Story', '2.5Fin'}, 'RoofStyle': {'Hip', 'Gable', 'Flat', 'Gambrel', 'Shed', 'Mansard'}, 'RoofMatl': {'Tar&Grv', 'ClyTile', 'Metal', 'Membran', 'CompShg', 'WdShngl', 'Roll', 'WdShake'}, 'Exterior1st': {'CBlock', 'AsphShn', 'ImStucc', 'WdShing', 'VinylSd', 'Plywood', 'CemntBd', 'Stucco', 'Stone', 'MetalSd', 'Wd Sdng', 'BrkComm', 'HdBoard', 'BrkFace', 'AsbShng'}, 'Exterior2nd': {'CBlock', 'AsphShn', 'ImStucc', 'VinylSd', 'Plywood', 'Stone', 'Stucco', 'Other', 'MetalSd', 'Wd Sdng', 'Wd Shng', 'HdBoard', 'CmentBd', 'Brk Cmn', 'BrkFace', 'AsbShng'}, 'MasVnrType': {'BrkCmn', 'Stone', 'NA', 'BrkFace', 'None'}, 'ExterQual': {'TA', 'Ex', 'Gd', 'Fa'}, 'ExterCond': {'Ex', 'Gd', 'Fa', 'Po', 'TA'}, 'Foundation': {'CBlock', 'Stone', 'Wood', 'Slab', 'PConc', 'BrkTil'}, 'BsmtQual': {'Ex', 'Gd', 'Fa', 'NA', 'TA'}, 'BsmtCond': {'Gd', 'Fa', 'NA', 'Po', 'TA'}, 'BsmtExposure': {'Mn', 'Gd', 'No', 'Av', 'NA'}, 'BsmtFinType1': {'NA', 'BLQ', 'Rec', 'GLQ', 'ALQ', 'LwQ', 'Unf'}, 'BsmtFinType2': {'NA', 'BLQ', 'Rec', 'GLQ', 'ALQ', 'LwQ', 'Unf'}, 'Heating': {'Wall', 'GasA', 'Grav', 'OthW', 'GasW', 'Floor'}, 'HeatingQC': {'Ex', 'Gd', 'Fa', 'Po', 'TA'}, 'CentralAir': {'N', 'Y'}, 'Electrical': {'FuseP', 'FuseA', 'SBrkr', 'Mix', 'NA', 'FuseF'}, 'KitchenQual': {'TA', 'Ex', 'Gd', 'Fa'}, 'Functional': {'Mod', 'Maj1', 'Typ', 'Sev', 'Min2', 'Maj2', 'Min1'}, 'FireplaceQu': {'Ex', 'Gd', 'Fa', 'NA', 'Po', 'TA'}, 'GarageType': {'Detchd', 'Basment', 'CarPort', 'NA', 'BuiltIn', 'Attchd', '2Types'}, 'GarageFinish': {'RFn', 'NA', 'Fin', 'Unf'}, 'GarageQual': {'Ex', 'Gd', 'NA', 'Fa', 'Po', 'TA'}, 'GarageCond': {'Ex', 'Gd', 'NA', 'Fa', 'Po', 'TA'}, 'PavedDrive': {'N', 'Y', 'P'}, 'PoolQC': {'Ex', 'Fa', 'Gd', 'NA'}, 'Fence': {'MnPrv', 'MnWw', 'NA', 'GdPrv', 'GdWo'}, 'MiscFeature': {'NA', 'Shed', 'TenC', 'Gar2', 'Othr'}, 'SaleType': {'ConLw', 'Oth', 'Con', 'ConLD', 'COD', 'WD', 'New', 'ConLI', 'CWD'}, 'SaleCondition': {'Family', 'Alloca', 'Abnorml', 'AdjLand', 'Normal', 'Partial'}}\n",
            "Best threshold 40: accuracy 0.8130434782608695\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "import copy\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "################# entropoy\n",
        "# Tip: feel free to call scipy.stats.entropy.  Make sure to use log base 2.\n",
        "#\n",
        "# Input:\n",
        "# data_frame -- pandas data frame\n",
        "#\n",
        "# Output:\n",
        "# answer -- float indicating the empirical entropy of tyhe data in data_frame\n",
        "##############################################\n",
        "def entropy(data_frame):\n",
        "\n",
        "\t# default value until this function is filled in\n",
        "\tanswer = 0\n",
        "\thigh_count = data_frame.loc[data_frame['class'] == 'high'].shape[0]\n",
        "\tlow_count = data_frame.loc[data_frame['class'] == 'low'].shape[0]\n",
        "\t# print(\"high_count: \",high_count)\n",
        "\ttotal = high_count + low_count\n",
        "\t# print(\"total: \", total)\n",
        "\tif total == 0:\n",
        "\t\treturn 0\n",
        "\tpk = np.array([low_count/total, high_count/total])\n",
        "\tanswer = scipy.stats.entropy(pk,base=2)\n",
        "\treturn answer\n",
        "\n",
        "################# info_gain\n",
        "# Tip: this function should call entropy\n",
        "#\n",
        "# Inputs:\n",
        "# data_frame -- pandas data frame\n",
        "# attribute -- string indicating the attribute for which we wish to compute the information gain\n",
        "# domain -- set of values (strings) that the attribute can take\n",
        "#\n",
        "# Output:\n",
        "# answer -- float indicating the information gain\n",
        "################################################3\n",
        "def info_gain(data_frame, attribute, domain):\n",
        "\n",
        "\t# default value until this function is filled in\n",
        "\tanswer = 0\n",
        "\tremainder_attribute = 0\n",
        "\tfor d in domain:\n",
        "\t\tdata_frame_subset = data_frame.loc[data_frame[attribute] == d]\n",
        "\t\tweight = data_frame_subset.shape[0]/data_frame.shape[0]\n",
        "\t\t# print(\"weight: \", weight)\n",
        "\t\t# print(\"entropy(data_frame_subset): \",entropy(data_frame_subset))\n",
        "\t\tremainder_attribute += weight * entropy(data_frame_subset)\n",
        "\t# print(\"entropy(data_frame): \", entropy(data_frame))\n",
        "\tanswer = entropy(data_frame) - remainder_attribute\n",
        "\treturn answer\n",
        "\n",
        "######## Decision_tree class\n",
        "#\n",
        "# This class defines the data structure of the decision tree to be learnt\n",
        "############################\n",
        "class Decision_Tree:\n",
        "\n",
        "\t# constructor\n",
        "\tdef __init__(self,attribute,branches,label):\n",
        "\t\tself.attribute = attribute\n",
        "\t\tself.branches = branches\n",
        "\t\tself.label = label\n",
        "\n",
        "\t# leaf constructor\n",
        "\tdef make_leaf(label):\n",
        "\t\treturn Decision_Tree('class', {}, label)\n",
        "\n",
        "\t# node constructor\n",
        "\tdef make_node(attribute,branches):\n",
        "\t\treturn Decision_Tree(attribute, branches, None)\n",
        "\n",
        "\t# string representation\n",
        "\tdef __repr__(self):\n",
        "\t\treturn self.string_repr(0)\n",
        "\n",
        "\t# decision tree string representation\n",
        "\tdef string_repr(self,indent):\n",
        "\t\tindentation = '\\t'*indent\n",
        "\n",
        "\t\t# leaf string representation\n",
        "\t\tif self.attribute == 'class':\n",
        "\t\t\treturn f'\\n{indentation}class = {self.label}'\n",
        "\n",
        "\t\t# node string representation\n",
        "\t\telse:\n",
        "\t\t\trepresentation = ''\n",
        "\t\t\tfor value in self.branches:\n",
        "\t\t\t\trepresentation += f'\\n{indentation}{self.attribute} = {value}:'\n",
        "\t\t\t\trepresentation += self.branches[value].string_repr(indent+1)\n",
        "\t\t\treturn representation\n",
        "\n",
        "\t# classify a data point\n",
        "\tdef classify(self,data_point):\n",
        "\n",
        "\t\t# leaf\n",
        "\t\tif self.attribute == 'class':\n",
        "\t\t\treturn self.label\n",
        "\n",
        "\t\t# node\n",
        "\t\telse:\n",
        "\t\t\treturn self.branches[data_point[self.attribute]].classify(data_point)\n",
        "\n",
        "############# choose attribute\n",
        "# Tip: this function should call info_gain\n",
        "#\n",
        "# Inputs:\n",
        "# attributes_with_domains -- dictionary with attributes as keys and domains as values\n",
        "# data_frame -- pandas data_frame\n",
        "#\n",
        "# Output:\n",
        "# best_score -- float indicting the information gain score of the best attribute\n",
        "# best_attribute -- string indicating the best attribute\n",
        "#################################\n",
        "def choose_attribute(attributes_with_domains,data_frame):\n",
        "\n",
        "\t# default value until this function is filled in\n",
        "\tbest_score = 0\n",
        "\tbest_attribute = 'NA'\n",
        "\tfor attribute in attributes_with_domains:\n",
        "\t\tdomain = attributes_with_domains[attribute]\n",
        "\t\tinformation_gain = info_gain(data_frame,attribute,domain)\n",
        "\t\t# print(\"information_gain: \", information_gain)\n",
        "\t\tif information_gain > best_score:\n",
        "\t\t\tbest_score = information_gain\n",
        "\t\t\tbest_attribute = attribute\n",
        "\treturn best_score, best_attribute\n",
        "\n",
        "############# train decision tree\n",
        "# Tip: this is a recursive function that should call itself as well as\n",
        "# choose_attribute,  Decision_Tree.make_leaf, Decision_Tree.make_node\n",
        "#\n",
        "# Inputs:\n",
        "# data_frame -- pandas data frame\n",
        "# attributes_with_domains -- dictionary with attributes as keys and domains as values\n",
        "# default_class -- string indicating the class to be assigned when data_frame is empty\n",
        "# threshold -- integer indicating the minimum number of data points in data_frame to allow\n",
        "#              the creation of a new node that splits the data with some attribute\n",
        "#\n",
        "# Output:\n",
        "# decision_tree -- Decision_Tree object\n",
        "########################\n",
        "def train_decision_tree(data_frame,attributes_with_domains,default_class,threshold):\n",
        "\n",
        "\t# default value until this function is filled in\n",
        "\tif data_frame.shape[0] < threshold:\n",
        "\t\treturn Decision_Tree.make_leaf(default_class)\n",
        "\telif (data_frame['class'] == 'high').all() or (data_frame['class'] == 'low').all():\n",
        "\t\t# print(\"label: \",data_frame['class'].iloc[0])\n",
        "\t\tlabel = data_frame['class'].iloc[0]\n",
        "\t\treturn Decision_Tree.make_leaf(label)\n",
        "\telif not attributes_with_domains:\n",
        "\t\thigh_count = data_frame.loc[data_frame['class'] == 'high'].shape[0]\n",
        "\t\tlow_count = data_frame.loc[data_frame['class'] == 'low'].shape[0]\n",
        "\t\tif high_count > low_count:\n",
        "\t\t\treturn Decision_Tree.make_leaf('high')\n",
        "\t\telse:\n",
        "\t\t\treturn Decision_Tree.make_leaf('low')\n",
        "\n",
        "\tbest_score, best_attribute = choose_attribute(attributes_with_domains,data_frame)\n",
        "\t# print(best_attribute)\n",
        "\tdomains = attributes_with_domains[best_attribute]\n",
        "\tbranches = {}\n",
        "\tfor value in domains:\n",
        "\t\texamples_i = data_frame.loc[data_frame[best_attribute] == value]\n",
        "\t\tupdated_attributes = attributes_with_domains.copy()\n",
        "\t\tdel updated_attributes[best_attribute]\n",
        "\t\thigh_count = examples_i.loc[examples_i['class'] == 'high'].shape[0]\n",
        "\t\tlow_count = examples_i.loc[examples_i['class'] == 'low'].shape[0]\n",
        "\t\tclass_mode = 'low'\n",
        "\t\tif high_count > low_count:\n",
        "\t\t\tclass_mode = 'high'\n",
        "\t\tsubtree = train_decision_tree(examples_i,updated_attributes,class_mode,threshold)\n",
        "\t\t# print(\"subtree: \",subtree)\n",
        "\t\tbranches[value] = subtree\n",
        "\t\t# tree.branches[value] = subtree\n",
        "\t\t# tree = Decision_Tree.make_node(value,subtree)\n",
        "\ttree = Decision_Tree.make_node(best_attribute,branches)\n",
        "\n",
        "\treturn tree\n",
        "\n",
        "\t# return Decision_Tree.make_leaf(default_class)\n",
        "\n",
        "######### eval decision tree\n",
        "# Tip: this function should call decision_tree.classify\n",
        "#\n",
        "# Inputs:\n",
        "# decision tree -- Decision_Tree object\n",
        "# data_frame -- pandas data frame\n",
        "#\n",
        "# Output:\n",
        "# accuracy -- float indicating the accuracy of the decision tree\n",
        "#############\n",
        "def eval_decision_tree(decision_tree, data_frame):\n",
        "\n",
        "\t# default value until this function is filled in\n",
        "\taccuracy = 0\n",
        "\ttotal = 0\n",
        "\tcorrect = 0\n",
        "\tfor index, row in data_frame.iterrows():\n",
        "\t\ttrue_label = row['class']\n",
        "\t\t# print(index, dict(row))\n",
        "\t\tpredicted_label = decision_tree.classify(dict(row))\n",
        "\t\t# print(predicted_label)\n",
        "\t\ttotal += 1\n",
        "\t\tif predicted_label == true_label:\n",
        "\t\t\tcorrect += 1\n",
        "\taccuracy = correct/total\n",
        "\t# print(\"correct: \", correct)\n",
        "\t# print(\"total: \", total)\n",
        "\treturn accuracy\n",
        "\n",
        "########### k-fold cross-validation\n",
        "# Tip: this function should call train_decision_tree and eval_decision_tree\n",
        "#\n",
        "# Inputs:\n",
        "# train_data -- pandas data frame\n",
        "# test_data -- pandas data frame\n",
        "# attributes_with_domains -- dictionary with attributes as keys and domains as values\n",
        "# k -- integer indicating the number of folds\n",
        "# threshold_list -- list of thresholds to be evaluated\n",
        "#\n",
        "# Outputs:\n",
        "# best_threshold -- integer indiating the best threshold found by cross validation\n",
        "# test_accuracy -- float indicating the accuracy based on the test set\n",
        "#####################################3\n",
        "def cross_validation(train_data, test_data, attributes_with_domains, k, threshold_list):\n",
        "\n",
        "\t# default value until this function is filled in\n",
        "\tbest_threshold = threshold_list[0]\n",
        "\ttest_accuracy = 0\n",
        "\tbest_validation_accuracy = 0\n",
        "\t# data_x = train_data.drop('class', axis=1)\n",
        "\t# data_y = train_data['class']\n",
        "\t# print(train_data_y)\n",
        "\tkf = KFold(n_splits=k)\n",
        "\tfor threshold in threshold_list:\n",
        "\t\tfor train_index, validation_index in kf.split(train_data):\n",
        "\t\t\ttrain_data_split = train_data.iloc[train_index]\n",
        "\t\t\tvalidation_data_split = train_data.iloc[validation_index]\n",
        "\t\t\t# train_data_y = data_y.iloc[train_index]\n",
        "\t\t\t# validation_data_y = data_y.iloc[validation_index]\n",
        "\t\t\ttrained_decision_tree = train_decision_tree(train_data_split,attributes_with_domains,'low',threshold)\n",
        "\t\t\tvalidation_accuracy = eval_decision_tree(trained_decision_tree,validation_data_split)\n",
        "\t\t\tif validation_accuracy > best_validation_accuracy:\n",
        "\t\t\t\tbest_validation_accuracy = validation_accuracy\n",
        "\t\t\t\tbest_threshold = threshold\n",
        "\ttest_accuracy = eval_decision_tree(trained_decision_tree, test_data)\n",
        "\treturn best_threshold, test_accuracy\n",
        "\n",
        "############################ main\n",
        "# You should not need to change the code below\n",
        "#\n",
        "# This code performs the following operations:\n",
        "# 1) Load the data\n",
        "# 2) create a list of attributes\n",
        "# 3) create a dictionary that maps each attribute to its domain of values\n",
        "# 4) split the data into train and test sets\n",
        "# 5) train a decision tree while optimizing the threshold hyperparameter by\n",
        "#    10-fold cross validation\n",
        "#####################################\n",
        "\n",
        "#load data\n",
        "data_frame = pd.read_csv(\"categorical_real_estate.csv\")\n",
        "data_frame = data_frame.fillna('NA')\n",
        "# print(data_frame)\n",
        "\n",
        "# get attributes\n",
        "attributes = list(data_frame.columns)\n",
        "attributes.remove('class')\n",
        "\n",
        "# create dictionary that maps each attribute to its domain of values\n",
        "attributes_with_domains = {}\n",
        "for attr in attributes:\n",
        "\tattributes_with_domains[attr] = set(data_frame[attr])\n",
        "\n",
        "print(attributes_with_domains)\n",
        "#split data in to train and test\n",
        "train_data = data_frame.iloc[0:1000]\n",
        "test_data = data_frame.iloc[1000:]\n",
        "# t_data = train_data.iloc[0:3]\n",
        "# print(t_data['class'][0])\n",
        "# perform 10-fold cross-validation\n",
        "best_threshold, accuracy = cross_validation(train_data, test_data, attributes_with_domains, 10, [10,20,40,80,160])\n",
        "print(f'Best threshold {best_threshold}: accuracy {accuracy}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b4duyJrndK7s"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}